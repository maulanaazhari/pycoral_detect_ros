#!/usr/bin/env python3

from gzip import READ
import roslib
roslib.load_manifest("pycoral_ros")
import sys
import rospy
import cv2
import time
from std_msgs.msg import String
from sensor_msgs.msg import Image, CompressedImage
from vision_msgs.msg import Detection2DArray, Detection2D, BoundingBox2D, ObjectHypothesisWithPose
import numpy as np
import ros_numpy as rnp

from pycoral_ros.srv import DetectImage, DetectImageResponse, DetectCompressedImage, DetectCompressedImageResponse

from pycoral.adapters import common, detect
from pycoral.utils.dataset import read_label_file
from pycoral.utils.edgetpu import make_interpreter

# for video streamer
import socket
import imagezmq

class tpu_detector:

    def __init__(self, model, labels, threshold=0.5, device_path=None, compressed=False, display=False, topic_name="input", stream=False, address=None):
        rospy.loginfo("Loading model {}".format(model))

        self.compressed = compressed

        self.threshold = threshold
        self.interpreter = make_interpreter(model)
        self.interpreter.allocate_tensors()
        rospy.loginfo("Interpreter loaded")
        
        self.load_labels(labels)

        self.frame_id = ''
        self.stream = stream
        self.address = address
        if self.stream:
            if self.address is None:
                raise ValueError("You have to specify address for video streaming")

            self.init_streamer()

        if self.compressed:
            self.image_sub = rospy.Subscriber(topic_name+'/compressed', CompressedImage, self.detect_image_callback, queue_size=1)
        else:
            self.image_sub = rospy.Subscriber(topic_name, Image, self.detect_image_callback, queue_size=1)

        self.cv_image = None
        self.detect_image_timer = rospy.Timer(rospy.Duration(1.0/10.0), self.detect_image_timer_callback)

        self.compressed_image_srv = rospy.Service("/detect_compressed_image", DetectCompressedImage, self.detect_compressed_image_srv)
        self.image_srv = rospy.Service("/detect_image", DetectImage, self.detect_image_srv)

        self.detection_pub = rospy.Publisher('/detections', Detection2DArray, queue_size=1)
        self.detection_display_pub = rospy.Publisher('/detections_image', Image, queue_size=1)
        self.display = display

    def init_streamer(self):
        self.sender = imagezmq.ImageSender(connect_to=self.address, REQ_REP=False)
        self.name = "Detections"

    def stream_image(self, cv_image):
        ret_code, jpg_buffer = cv2.imencode(".jpg", cv_image, [int(cv2.IMWRITE_JPEG_QUALITY), 25])
        # self.sender.send_image(self.name, cv_image)
        self.sender.send_jpg(self.name, jpg_buffer)
        
    def detect_image_timer_callback(self, event=None):
        if self.cv_image is None:
            return
        cv_image = self.cv_image.copy()

        detections = self.detect_image(cv_image, self.frame_id)
        self.detection_pub.publish(detections)
        self.publish_image(detections, cv_image)

    def detect_image(self, cv_image, frame_id=""):
        _, scale = common.set_resized_input(self.interpreter, cv_image.shape[0:2][::-1], lambda shape: cv2.resize(cv_image, shape, interpolation = cv2.INTER_AREA))

        start = time.perf_counter()
        self.interpreter.invoke()
        inference_time = time.perf_counter() - start
        objs = detect.get_objects(self.interpreter, self.threshold, scale)
        
        detections = Detection2DArray()
        now = rospy.get_rostime()
        
        imheight, imwidth, _ = cv_image.shape

        for detection in objs:
            min_x, min_y, max_x, max_y = detection.bbox.xmin, detection.bbox.ymin, detection.bbox.xmax, detection.bbox.ymax

            centre_x = (max_x+min_x)/2.0
            centre_y = (max_y+min_y)/2.0
            height = max_y-min_y
            width = max_x-min_x
            
            if height <=0 or width <= 0:
              continue
            
            bbox = BoundingBox2D()
            bbox.center.x = centre_x
            bbox.center.y = centre_y
            bbox.size_x = width
            bbox.size_y = height
            
            hypothesis = ObjectHypothesisWithPose()
            hypothesis.id = detection.id
            hypothesis.score = detection.score
            hypothesis.pose.pose.position.x = centre_x
            hypothesis.pose.pose.position.y = centre_y

            crop = cv_image[int(min_y):int(max_y), int(min_x):int(max_x)].astype('uint8')

            if(crop.shape[0]<=0 or crop.shape[1] <=0):
                continue

            res, buffer = cv2.imencode(".png", crop)

            instance = Detection2D()
            instance.header.stamp = now
            instance.header.frame_id = frame_id
            instance.results.append(hypothesis)
            instance.bbox = bbox
            instance.source_img.data = np.array(buffer).tostring()
            instance.source_img.header.frame_id = frame_id
            instance.source_img.header.stamp = now

            detections.detections.append(instance)

        rospy.loginfo("%.2f ms" % (inference_time*1000))
        rospy.loginfo("detections: {}".format(len(detections.detections)))

        return detections

    def detect_compressed_image_srv(self, req):
        rospy.loginfo("Image service is called!")
        np_image = np.frombuffer(req.image.data, dtype=np.uint8)
        cv_image = cv2.imdecode(np_image, cv2.IMREAD_UNCHANGED)
        detections = self.detect_image(cv_image)
        self.publish_image(detections, cv_image)
        return DetectCompressedImageResponse(detections)

    def detect_image_srv(self, req):
        rospy.loginfo("Image service is called!")
        cv_image = rnp.numpify(req.image)
        detections = self.detect_image(cv_image)
        self.publish_image(detections, cv_image)
        return DetectImageResponse(detections)

    def detect_image_callback(self, data):
        self.frame_id = data.header.frame_id

        if self.compressed:
            np_image = np.frombuffer(data.data, dtype=np.uint8)
            cv_image = cv2.imdecode(np_image, cv2.IMREAD_UNCHANGED)
        else:
            cv_image = rnp.numpify(data)

        self.cv_image = cv_image

    def display_detection(self, detections, cv_image):
        cv_image_display = cv_image.copy()

        for det in detections.detections:
            min_x = int(det.bbox.center.x - det.bbox.size_x//2)
            max_x = int(det.bbox.center.x + det.bbox.size_x//2)
            min_y = int(det.bbox.center.y - det.bbox.size_y//2)
            max_y = int(det.bbox.center.y + det.bbox.size_y//2)

            cv_image_display = self.add_annotation(cv_image_display, det.results[0].id, (min_x, min_y), (max_x, max_y), det.results[0].score)
        
        cv2.imshow('Results', cv_image_display)
        cv2.waitKey(0)

    def publish_image(self, detections, cv_image):
        cv_image_display = cv_image.copy()

        for det in detections.detections:
            min_x = int(det.bbox.center.x - det.bbox.size_x//2)
            max_x = int(det.bbox.center.x + det.bbox.size_x//2)
            min_y = int(det.bbox.center.y - det.bbox.size_y//2)
            max_y = int(det.bbox.center.y + det.bbox.size_y//2)

            cv_image_display = self.add_annotation(cv_image_display, det.results[0].id, (min_x, min_y), (max_x, max_y), det.results[0].score)
        
        msg = rnp.msgify(Image, cv_image_display, encoding='bgr8')
        msg.header.frame_id = self.frame_id
        # cv2.imshow('Results', cv_image_display)
        # cv2.waitKey(1)

        self.detection_display_pub.publish(msg)
        if self.stream:
            self.stream_image(cv_image_display)

    # def detect_image_callback(self, data):
    #     if self.compressed:
    #         np_image = np.frombuffer(data.data, dtype=np.uint8)
    #         cv_image = cv2.imdecode(np_image, cv2.IMREAD_UNCHANGED)
    #     else:
    #         cv_image = rnp.numpify(data)

    #     if self.display:
    #         cv_image_display = cv_image.copy()

    #     _, scale = common.set_resized_input(self.interpreter, cv_image.shape[0:2][::-1], lambda shape: cv2.resize(cv_image, shape, interpolation = cv2.INTER_AREA))

    #     start = time.perf_counter()
    #     self.interpreter.invoke()
    #     inference_time = time.perf_counter() - start
    #     objs = detect.get_objects(self.interpreter, self.threshold, scale)
        
    #     detections = Detection2DArray()
    #     now = rospy.get_rostime()
        
    #     imheight, imwidth, _ = cv_image.shape

    #     for detection in objs:
    #         min_x, min_y, max_x, max_y = detection.bbox.xmin, detection.bbox.ymin, detection.bbox.xmax, detection.bbox.ymax
            
    #         if self.display:
    #             cv_image_display = self.add_annotation(cv_image_display, detection.id, (min_x, min_y), (max_x, max_y), detection.score)

    #         centre_x = (max_x+min_x)/2.0
    #         centre_y = (max_y+min_y)/2.0
    #         height = max_y-min_y
    #         width = max_x-min_x
            
    #         if height <=0 or width <= 0:
    #           continue
            
    #         bbox = BoundingBox2D()
    #         bbox.center.x = centre_x
    #         bbox.center.y = centre_y
    #         bbox.size_x = width
    #         bbox.size_y = height
            
    #         hypothesis = ObjectHypothesisWithPose()
    #         hypothesis.id = detection.id
    #         hypothesis.score = detection.score
    #         hypothesis.pose.pose.position.x = centre_x
    #         hypothesis.pose.pose.position.y = centre_y

    #         crop = cv_image[int(min_y):int(max_y), int(min_x):int(max_x)].astype('uint8')

    #         if(crop.shape[0]<=0 or crop.shape[1] <=0):
    #             continue

    #         res, buffer = cv2.imencode(".png", crop)

    #         instance = Detection2D()
    #         instance.header.stamp = now
    #         instance.header.frame_id = data.header.frame_id
    #         instance.results.append(hypothesis)
    #         instance.bbox = bbox
    #         instance.source_img.data = np.array(buffer).tostring()
    #         instance.source_img.header.frame_id = data.header.frame_id
    #         instance.source_img.header.stamp = now

    #         detections.detections.append(instance)

    #     rospy.loginfo("Detected: {}".format(len(detections.detections)))
            
    #     if len(objs) > 0:
    #         self.detection_pub.publish(detections)

    #     if self.display:
    #         cv2.imshow('Results', cv_image_display)
    #         cv2.waitKey(1)
        
    #     rospy.loginfo("%.2f ms" % (inference_time*1000))

    def load_labels(self, labels):
        with open(labels, 'r', encoding="utf-8") as f:
            pairs = (l.strip().split(maxsplit=1) for l in f.readlines())
            self.labels = dict((int(k), v) for k, v in pairs)

    def add_annotation(self, img, class_id, start_point, end_point, score):
        cv2.rectangle(img, start_point, end_point, (255, 0, 0), 2, lineType=cv2.LINE_8)
        cv2.putText(
            img, 
            "{}:{}%".format(self.labels[class_id], round(score*100)), 
            start_point, 
            fontFace=cv2.FONT_HERSHEY_DUPLEX, 
            fontScale=0.5, 
            color=(255, 0, 0),
            thickness=1,
            lineType=cv2.FILLED
        )
        return img

def main(args):

    rospy.init_node('detect', anonymous=True)
    
    model_path = rospy.get_param('~model_path')
    label_path = rospy.get_param('~label_path')
    compressed = rospy.get_param('~compressed')
    threshold = rospy.get_param('~threshold', default=0.35)
    device_path = rospy.get_param('~device_path', default=None)
    display = rospy.get_param('~display', default=False)
    topic_name = rospy.get_param('~topic_name', default="input")
    stream = rospy.get_param('~stream', default=False)
    address = rospy.get_param('~address', default='tcp://*:5555')

    detector = tpu_detector(model_path, label_path, threshold, device_path, compressed, display, topic_name, stream, address)

    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")

if __name__ == "__main__":
    main(sys.argv)
